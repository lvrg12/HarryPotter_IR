import nltk

def tokenize( doc ):
    return nltk.word_tokenize(doc)

def normalize( doc ):
    return []

def lemmitize( doc ):
    return []

def stem( doc ):
    return []